{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feynman Machine: The Universal Dynamical Systems Computer\n",
    "\n",
    "https://arxiv.org/abs/1609.03971\n",
    "\n",
    "pdf: https://arxiv.org/pdf/1609.03971.pdf\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences between Feynman Machines and existing Deep Learning Networks\n",
    "\n",
    "pg 2-3/28\n",
    "\"Due to the much higher density and locality of processing, a Feynman Machine-based system can perform at least comparably while dramatically reducing the footprint in computational power, training data and fine-tuning.\n",
    "\n",
    "Feynman Machines can be arbitrarily split into modules distributed across clusters and the Internet, and systems running on low power devices such as phones can be dynamically and robustly augmented using low-bandwidth connections to larger networks running in the cloud. Models can be trained on powerful infrastructure and transferred for operation and further custom learning on smaller devices. Importantly, the same architecture can be used as a component in unsupervised, semi-supervised, fully supervised and reinforcement learning contexts. A variant - the Routed Predictive Hierarchy - is described, which allows a Feynman Machine to directly control a traditional Deep Learning network by switching it to use spatiotemporally-selected subnetworks.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamical Systems\n",
    "\n",
    "pg 3/28\n",
    "\n",
    "\"A Dynamical System is a mathematical model whose dynamics are characterised by express update rules, typically differential equations in continuous systems, or difference equations in discrete time (a comprehensive survey of Dynamical Systems is (Strogatz, 2014)).\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pg 4/28\n",
    "\n",
    "\"A soccer player who runs into the box to head a crossed ball into the net is clearly not solving the simultaneous differential equations of a spinning ball’s motion through moving air, under gravity, nor is his run the result of preplanning a sequence of torques generated by his muscles. The player’s brain has a network of dynamical systems models which have, through practise and experience, learned to predict the flight of the ball and plan a sequence of motor outputs which will, along with intermediate observational updates and corrections, lead to the desired performance of his skill.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feynman Machine Architecture\n",
    "\n",
    "pg 4/28\n",
    "\n",
    "\"A Feynman Machine is a collection of Dynamical Systems modules called regions, connected together in a network or hierarchy, and to its external world, via sensorimotor channels, each of which carries a (usually high-dimensional) time series signal of some kind. Each region is capable of adaptively learning, representing, predicting and interacting with the spatiotemporal, sensorimotor structure of its “world”. The internal structure of a region may\n",
    "vary from a single monolithic component to an internal network of components which are each capable of performing part of the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pg 5/28\n",
    "\n",
    "\"Unlike the Turing Machine (or any digital computer), the Feynman Machine is not “programmed” in the everyday sense. Instead, the structure of the network, the choice and configuration of regions, and connections to its external world together dictate the functionality and capability of the system, and the actual performance is achieved by online learning of the structure in the world. In natural settings such as neocortex, these hyperparameters are chosen by genetic inheritance and adapted during development. In artificial settings, the setup of the system is the primary design task for the implementor, as illustrated in several examples later in this paper.\"\n",
    "\n",
    "\"In the neocortex, a region corresponds to a multilayer patch of grey matter several millimeters square, sometimes referred to as a cortical macrocolumn or cortical column, several or many such patches being combined to form a “brain region” such as V1. In our artificial systems, a region is often synonymous with a layer or level in a hierarchy, and our description uses the term “layer” for that reason.\n",
    "\n",
    "\"A Feynman Machine region typically has two “faces”: the “visible”, “downward” or “input” face and the “hidden”, “upward” or “output” face. Each face has both inputs and outputs, but their semantics are different for each face. The “visible inputs” correspond to sensorimotor inputs to the region, and the “visible outputs” to predictions of future inputs, feedback predictive signals to lower Regions and/or control/behavioral/attention signals. The “hidden outputs” correspond to encodings of the visible inputs which are directed to visible inputs in higher regions, and the “hidden inputs” receive feedback/control/attention/routing signals from higher regions’ visible outputs.\n",
    "\n",
    "\"In addition, recurrent internal channels in a region connect internal components. For example, in the Sparse Predictive Hierarchy described later, the hidden output (the predictive encoding) is combined with the hidden input (feedback from above) and fed downward through a decoder to generate a visible output prediction of the next input, and then this is compared with the real next input to generate a prediction error and drive learning. In neocortex, the considerable intralaminar connections serve similar purposes in order to support autonomous region-level learning and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
